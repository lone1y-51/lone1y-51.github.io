
- [[#llama_index调研|llama_index调研]]
	- [[#llama_index调研#TreeIndex|TreeIndex]]
	- [[#llama_index调研#KnowGraphIndex|KnowGraphIndex]]
- [[#部分算法调研|部分算法调研]]
	- [[#部分算法调研#最大边际相关性（mmr）|最大边际相关性（mmr）]]
- [[#langchain调研|langchain调研]]
	- [[#langchain调研#ConversationalRetrievalChain|ConversationalRetrievalChain]]
- [[#推荐系统调研|推荐系统调研]]
	- [[#推荐系统调研#基础框架结构|基础框架结构]]
		- [[#基础框架结构#物料数据|物料数据]]
		- [[#基础框架结构#用户数据 & 用户画像|用户数据 & 用户画像]]
		- [[#基础框架结构#实时计算|实时计算]]
		- [[#基础框架结构#算法模块|算法模块]]
		- [[#基础框架结构#推荐引擎|推荐引擎]]
		- [[#基础框架结构#数据报表|数据报表]]
	- [[#推荐系统调研#数据模块|数据模块]]
		- [[#数据模块#物料数据|物料数据]]
			- [[#物料数据#存储|存储]]
			- [[#物料数据#正排和倒排索引|正排和倒排索引]]
			- [[#物料数据#用户行为数据 & 画像|用户行为数据 & 画像]]
			- [[#物料数据#物料信息挖掘|物料信息挖掘]]
			- [[#物料数据#实时计算|实时计算]]
	- [[#推荐系统调研#推荐引擎|推荐引擎]]
		- [[#推荐引擎#实验染色|实验染色]]
		- [[#推荐引擎#召回|召回]]
			- [[#召回#兴趣内容召回|兴趣内容召回]]
			- [[#召回#协同过滤召回|协同过滤召回]]
			- [[#召回#算法类召回|算法类召回]]
		- [[#推荐引擎#排序|排序]]
			- [[#排序#重排序|重排序]]
	- [[#推荐系统调研#特征库|特征库]]
		- [[#特征库#训练数据|训练数据]]
			- [[#训练数据#样本处理|样本处理]]
			- [[#训练数据#模型训练|模型训练]]
	- [[#推荐系统调研#预测|预测]]


# llama_index调研
## TreeIndex
1. 用普通的方式切分文档，形成一个个node(理解为文本块)，拼为一个数组
2. 按照一个数字 a（默认是10）按照数组顺序，分批给这些Node生成summary，每一批生成一个node，并设置为这一组节点的parent。将这个parent放到node列表的最后面，并且从列表中移除这一批node。
4. 重复这个步骤，直到数组列表的长度不满足a，余下的节点就是root节点。
5. 使用的时候，每层询问gpt哪个节点是相关的，然后使用相关节点逐层调用直到叶子节点

## KnowGraphIndex
1. 用普通的方式切分文档，形成一个个node(理解为文本块)，拼为一个数组
2. 用gpt把每个node的文本生成一组类似主+谓+宾的三元组
```
    "Some text is provided below. Given the text, extract up to "
    "{max_knowledge_triplets} "
    "knowledge triplets in the form of (subject, predicate, object). Avoid stopwords.\n"
    "---------------------\n"
    "Example:"
    "Text: Alice is Bob's mother."
    "Triplets:\n(Alice, is mother of, Bob)\n"
    "Text: Philz is a coffee shop founded in Berkeley in 1982.\n"
    "Triplets:\n"
    "(Philz, is, coffee shop)\n"
    "(Philz, founded in, Berkeley)\n"
    "(Philz, founded in, 1982)\n"
    "---------------------\n"
    "Text: {text}\n"
    "Triplets:\n"
```
3. 用主语做key 生成一个  {主：(谓，宾)}。 -> a
4. 主语和宾语分别做key 生成一个 {key: node}的缓存 -> b，一个key可以对应多个node
5. 将待查询的问题也生成类似几组类似三元组
6. 把生成三元组的所有keyword都通过 b的map去找一遍node，给node计数，统计出被命中次数最多的node，node的文本就是知识
7. （可选）可以根据a查找关联的keyword，重复步骤6

# 部分算法调研
## 最大边际相关性（mmr）
有一个查询向量记作 a，有一组备选记作 B，有个预设的权重记作q
1. 计算a与B中每个元素的相关性记作C
2. 把最大的那个放到结果列表里记作S
3. 把B中每个元素分别和S中的元素计算相关性记作D
5. 循环B，用Ci，Di，和q计算一个值 $q \times Ci - （1-q）\times Di$ ，把结果最大的那个放入S
6. 循环2-5，直到找到合适个数的结果

# langchain调研
## ConversationalRetrievalChain
这个chain是结合上下文进行对话的chain
文档翻译
```
用于根据检索到的文档进行对话的链。

    该链接收聊天历史记录（消息列表）和新问题，
    然后返回该问题的答案。
    该链的算法由三部分组成：

    1. 使用聊天记录和新问题创建“独立问题”。
    这样做是为了让这个问题可以传递到检索​​步骤来获取
    相关文件。如果只传入新问题，则相关上下文
    可能有所欠缺。如果整个对话都被传递到检索​​中，则可能有
    那里有不必要的信息，会分散检索的注意力。

    2. 这个新问题被传递给检索器，并且相关文档被传递
    回。

    3. 检索到的文件与新问题一起传递给法学硕士
    （默认行为）或原始问题和聊天记录生成最终
    回复。
```
`CONDENSE_QUESTION_PROMPT`这个prompt是上下文改写的的prompt
# 推荐系统调研
这个调研主要参考和学习了[这篇文章](https://zhuanlan.zhihu.com/p/143816066)
## 基础框架结构
这里罗列出了要实现一个好的推荐系统应该具备的一些基础信息
### 物料数据
简单点可以理解为待推荐的内容。要多，而且要足够丰富。
### 用户数据 & 用户画像
被大家痛恨的系统要收集的数据，各种操作/浏览等数据，方便做用户画像。好的用户画像和全量的用户操作数据可以更针对性的进行推荐。
### 实时计算
这个模块我简单的理解为用户画像的实时更新，因为在大流量，大数据量的情况下实时性是一个比较重要的课题，所有系统都要面临的困难。
### 算法模块
字面意思，这个模块特指推荐算法，不过文章里特地说明了物料数据不能直接用作训练数据。原文如下：
> 但此数据非彼数据，算法需要用的还需要转化为特征和样本数据，绝大部分算法模型还是很挑食的，喂进去的数据必须要经过处理，否则再好的模型面对噪声数据也不会有好的结果。

### 推荐引擎
分为了两类，离线版和在线版。
离线版指的是对推荐的实时性要求不高的场景。这种场景可以采用定时等策略周期性的生成推荐数据。
在线版指业务实时性要求高的场景（导购推荐就属于这一类）。这类场景需要针对性搭建推荐引擎，整合各个模块，包括但不限于建倒排索引、召回、排序、rerank等。
如何评估推荐系统的好坏，这里提到一个名词叫做**分桶实验系统**。
### 数据报表
这个模块我理解为效果评估和展示，方便系统直观的看到整个推荐系统的运行效果。直接贴原文：
>截止目前一套完整的数据流已经可以跑通了，也可以为用户推荐计算好的结果，但还需要一个看起来不起眼却非常重要的模块——报表数据，用来展示推荐系统整体效果，包括AB实验效果，分标签、召回等维度效果等，用于后续迭代优化时提供数据支撑。

## 数据模块
数据模块整体分为物料数据和用户数据，物料数据是需要进行严格的格式化的。
### 物料数据
#### 存储
这里比较简单，就是根据团队当前的现状寻找一个合适的存储方式。不过特殊说明了两点，第一需要有唯一id，第二必须要是结构化的。
#### 正排和倒排索引
两个名词，文章中说的比较简单，就是物料数据可以根据结构化之后的标签进行搜索和排序，排序分为正序排列和倒序排列。其实类似搜索引擎的概念。某些存储引擎天然都有倒排索引，比如es。
#### 用户行为数据 & 画像
通过某种方式记录用户行为（比如日志），但是也需要结构化，而且最好和物料进行结合。
用户画像，其实就是通过某种计算方法，计算出用户偏爱的某类物料，有个公式（不清楚通用性）


$${score_k} = {{\Sigma{\alpha_i\omega_if(t_i)}}\over{N_b}}$$
> score为关键词k的兴趣得分，分子是用户对所有行为物料中带有关键词k的兴趣累加，i为用户行为中的第i个物料，α为对该物料行为权重，比如点赞就比点击的权重要高，ω为关键词k在物料上的权重分，f(t)是一个时间衰减函数，表明用户在某一时刻对物料关键词的兴趣衰减程度，距离当前时间越长，感兴趣的衰减程度越高。分母是所有行为物料的个数。所有关键词计算出score值后再进行归一化排序，即可得出用户在关键词兴趣上的偏好序列。其他维度依赖的计算方式类似，但各维度计算结果都是带权重分的多值列表，毕竟用户也没实打实告诉你他的真实偏好（可能他自己也不知道）。
> 通过这种方式可以初步定量计算用户偏好，但验证和评估不好定量，而且只考虑显示行为反馈信息，隐式反馈如曝光未点击、停留时长这类“不感兴趣”的影响未考虑在内，需要后续再去优化迭代。

这个公式计算出来的结果是显示画像，因为所有的结果都有一个明确的说法和来源。
还有一类就是隐士画像，这类画像就是比较玄学的那一类，通过embedding和聚类都算法隐士的计算出用户的兴趣，这类算法具有**不可解释性**
#### 物料信息挖掘
通过记录用户行为也间接记录了物料被使用的情况，这些数据同理也可以被拿来计算物料在时间维度上的表现，作为算法的一个特征。
#### 实时计算
主要针对用户实时的一些操作进行实时的反馈，例如点赞后疯狂推荐这种。也可以对一些新上线的物料进行实时的调整（效果不好的物料权重会逐渐降低）。
## 推荐引擎
> 推荐引擎核心功能的主要有用户请求解析、实验分桶染色、召回、排序、重排等模块。

我理解的属于推荐引擎的范畴是从数据侧拿到召回结果之后，到展示给用户之前都属于推荐引擎的范畴。
### 实验染色
这里提到了A/B测试。类似于把一批人灰度到另一种推荐策略下观察效果，对比两种策略的优劣。我认为这个需要系统的进阶功能。
![[Pasted image 20230828102655.png]]
### 召回
也就是初筛，从完整的物料库里筛出一批用户可能感兴趣的（**粗排阶段**）。分类两种策略：
1. 兴趣内容召回
2. 协同过滤召回
#### 兴趣内容召回
结合用户画像和物料的标签根据用户喜好进行召回
> 基于用户兴趣画像，匹配不同维度物料，用户喜欢体育类的，那就从体育类内容中选取最新/最热内容召回，非常直观且可解释性强。根据不同维度组成一级或多级索引可以组成多路兴趣召回，因为用户画像中各维度兴趣点都有权重，那召回对应物料的数量可根据权重自适应调整

#### 协同过滤召回
协同过滤召回又可以分为基于用户的和基于物料的
基于用户的原则是**将跟你看过相同物料的用户，他们看过的物料推荐给你**，也就是其他人看过这个概念，叫做`User Collaborative Filtering——UCF`
基于物料的原则是 **将你看过物料的相似物料推荐给你**，也就是相似推荐，叫做`Item Collaborative Filtering——ICF`。
这两种原则都有一个寻找相似物（用户/物料）的过程。计算相似度有Jaccard相似度、余弦相似度、皮尔逊相似度等（现在可能更多）。
基于UCF的基本流程如下：
> 1、拿到所有用户对应操作行为的物料，及user: item1,item2,item3...  
> 2、对全量用户计算两两用户间相似度得分  
> 3、对每个用户获取到得分排序最高的topN用户  
> 4、获取topN用户的历史行为item并与目标用户的item做去重  
> 5、将去重后的item存入以目标用户为key的redis中，userid:"item1,item2,item3...."

基于ICF的流程基本一致，但是在计算相似度时有些区别，物料有些是多媒体数据，就需要一个embedding模型将数据向量化，方便之后的计算。
#### 算法类召回
> 严格来说协同过滤和各类embedding也是算法，但这里算法类召回主要聚焦于通过特征和模型来对所有物料进行排序，筛选出topN物料进入候选集，也就是常说的粗排。因为要在线对万到千万级别的物料进行排序，对计算性能有严格要求，因此这类算法需要模型较为简单，特征较少，主要使用线性模型例如LR、FM、GBDT等。

这三类召回方法可以配合使用。但是召回的候选集有一些疑难杂症需要解决
1. 召回的多样性，三个算法都是为了召回更精准匹配用户兴趣的数据，所有推荐的圈子会越来越小，无法保证多样性。
2. 数据的冷启动，如何确保一些新的物料或者说原本评估为质量不高的物料的重新启用。

### 排序
**精排阶段**，初始搭建可以使用LR或GBDT等线性模型快速实现上线
#### 重排序
这类要控制的是同类内容打散，跟进用户的实时行为，时政热点，热点内容等等。
## 特征库
这部分的干货太多，不好总结，直接摘抄片段了
总结就是，特征库服务于算法和模型，需要根据实际业务进行匹配，基本方法和理论就那么几种，但是调好的特征工程很少。
> 算法需要数据，数据需要特征，特征是模型训练数据中最重要的部分，**各类算法的本质也是根据现有样本分布拟合出一个最接近真实情况的概率分布函数**，需要拟合的参数就是各个特征，通过这个函数即可获取特定用户或物料的特征下用户对物料的感兴趣程度（点击的概率）

> 推荐系统连接的是人与物，特别是独特业务场景下的人与物，那么一定也会有独特的物料属性特征与用户行为特征，针对深入理解业务的基础上构造好的特征，那推荐算法出来的结果也就成功了一半以上。从人和物的角度，特征也分为物料特征、用户特征及上下文特征，上下文也可算作用户特征的一种。用户特征一般通过明确记录或统计挖掘得到，如用户的地理位置、访问时段、使用设备、性别年龄（可能通过填写资料获取）一般在访问时即可拿到；挖掘特征通过历史用户的操作行为，统计用户的画像偏好。物料特征一般是物料自身属性及其统计数据，例如类别、关键词、主题等固有属性，以及历史一段时间窗口内的效果统计如曝光、点击、点赞、转发等

> 特征工程是一项实践性很强的工作，基本的技术方法就那么几种，但真正用来调好模型的特征工程方法一般网上也很少，原因之一就在于是跟自己公司具体业务挂钩的，不具有普遍性，即使放出来也只适用于自己公司业务，无法放之四海而皆准

有了这些特征，就有了用来训练的基础数据。
### 训练数据
> 各类算法只是针对大量样本数据的一个拟合过程，拟合出一个接近真实数据分布的概率分布函数，即所谓的“规律”

> 需要对整个样本集做处理，否则会引入大量噪声，不能让模型很好的拟合出样本分布。

#### 样本处理
非真实访问样本（举例就是爬虫得到的数据），极少行为的样本，此类数据需要按需剃除（比如去除一些方差较大的数据），避免带来极端的噪声。
特征缺失，针对一些特殊值进行抛弃或者均值处理。
正负样本的选择。
#### 模型训练
这部分内容相对较少，文章推荐选用LR或GBDT跑一个线性模型，作者的意见是深度学习是头部企业的专属，中小型企业可以使用主流的线性模型，通过分析用户行为及数据，构建特征工程及样本数据优化，得来的效果要比深度学习模型更好
## 预测
这里就是一个执行流程的问题了，直接贴原文吧
> 通常线上使用预测服务的形式实时提供模型推断功能，这时需要通过推荐引擎接口将待排序候选集的物料id、用户id以及请求上下文信息传给预测服务。预测服务中也分为特征抽取、物料打分排序、模型同步校验等模块。通过传入的物料id及用户id，可以从特征库中在线抽取特征，结合上下文特征得到所有候选集的特征信息，进而通过模型中各特征权重，计算每个物料的打分。这个过程中注意被抽取的特征id要同训练好模型中的特征权重id保持一致，同时各物料特征抽取和打分过程可以通过并行化方式提升系统性能。训练好的模型由离线训练流程定时同步到线上预测服务机器，注意同步时需要同时把模型的checksum一并同步并在服务端进行校验，当同步失败时仍使用缓存的上次同步模型进行预测，避免数据不一致。候选集物料被打分后进行整体排序，结果返回给推荐引擎。

